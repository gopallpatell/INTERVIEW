RDS
RDS is a managed database service by AWS where AWS takes care of database setup, maintenance, backups, and scaling.
RDS lets you run relational databases in the cloud without managing servers manually.
Relational means data is stored in tables that are connected (related) to each other.
Data is stored in tables
Tables have rows and columns
Tables are linked using keys (relationships)

Why relational databases are used
Data is structured
Easy to query using SQL
Maintains data consistency
Avoids duplicate data

‚úÖ Fully managed ‚Äì no OS or DB admin headache
AWS manages:
OS installation & patching
Database software updates
Monitoring & maintenance
üëâ You don‚Äôt log into the server or manage the database manually.

‚úÖ High availability ‚Äì Multi-AZ deployments
RDS automatically creates a standby replica in another Availability Zone
If the primary DB fails, AWS automatically switches to the standby
üëâ Zero/low downtime during failures.

‚úÖAutomated Backups & Snapshots ‚Äì point-in-time recovery
Daily automatic backups
Transaction logs saved continuously
You can restore the database to any specific time (e.g., 10:35 AM yesterday)
üëâ Protects against accidental data deletion.

‚úÖ Scalable ‚Äì increase storage & compute easily
Increase CPU, RAM, or storage with a few clicks or API
No need to stop the application for most scaling tasks

üëâ Handles traffic growth smoothly.
‚úÖ Secure ‚Äì IAM, VPC, encryption, security groups
RDS security includes:
IAM for access control
VPC for network isolation
Security Groups as firewall rules
Encryption at rest & in transit
üëâ Suitable for enterprise & healthcare/finance apps.

RDS supports popular SQL databases:
MySQL
PostgreSQL
MariaDB
Oracle
SQL Server
Amazon Aurora

Healthcare / enterprise setup
Multi-AZ ‚ÜíAZ failure protection
Automated backups ‚Üí logical failure recovery
Cross-region replica ‚Üí region-level DR

Amazon RDS supports disaster recovery using Multi-AZ deployments, automated backups, snapshots, and cross-region read replicas depending on the recovery requirements.
I use Amazon RDS by creating a managed database instance inside a VPC, securing it with security groups, connecting it to my application using the RDS endpoint, and relying 
on built-in backups, Multi-AZ, and monitoring for reliability.

What you need to connect to RDS
on Client EC2
sudo apt install postgresql-client -y
sudo apt install mysql-client -y
mysql -h <rds-endpoint> -u admin -p

From Application (No manual client needed)
If your app uses:
Java (JDBC)
Node.js (mysql / pg library)
Python (psycopg2 / pymysql)

Important networking rule (very common mistake)
Even if client is installed, connection will fail unless:
Security Group allows DB port
RDS & client are in same VPC (or via VPN/peering)
Correct username/password

IN EKS
Store DB credentials in Kubernetes Secret

apiVersion: v1
kind: Pod
metadata:
  name: rds-test
spec:
  containers:
  - name: postgres-client
    image: postgres:15
    env:
    - name: DB_HOST
      valueFrom:
        secretKeyRef:
          name: rds-secret
          key: DB_HOST
    - name: DB_USER
      valueFrom:
        secretKeyRef:
          name: rds-secret
          key: DB_USER
    - name: DB_PASSWORD
      valueFrom:
        secretKeyRef:
          name: rds-secret
          key: DB_PASSWORD
    - name: DB_NAME
      valueFrom:
        secretKeyRef:
          name: rds-secret
          key: DB_NAME
    command: ["sleep", "3600"]

after all this we can connect the client to DB and to create table in DB wwe need to run the quary
it is structured quaery language. it uses tables to store the data.
   - The INSERT INTO statement is used to add new records to a table. 
   - The UPDATE statement is used to modify existing records in a table. 
   - The DELETE statement is used to remove records from a table.
   - The CREATE TABLE statement is used to create a new table in a database.
   - The DROP TABLE statement is used to delete a table and all its data.
   - The JOIN clause is used to combine rows from two or more tables, based on a related column.

using all this we can create and insert the data in table and rows     






DYnamodb
it is serverless we dont need to create server

DynamoDB is Amazon‚Äôs fully managed NoSQL database service. DynamoDB stores data as key‚Äìvalue or JSON documents and is built for very high speed and massive scale.

Amazon DynamoDB is ideal for applications that require fast, flexible, and scalable database solutions. It's commonly used for web and mobile applications, 
e-commerce platforms, IoT systems, real-time data processing, gaming, and more.

Amazon DynamoDB is a fully managed, serverless NoSQL key-value and document database designed for high performance and massive scalability.

SQL databases use structured tables with fixed schemas and support relationships, while NoSQL databases use flexible schemas and are designed for high scalability and 
performance.      ####  Schema is the predefined structure that defines how data is stored, including fields and data types.

Use SQL for structured, transactional, relational data; use NoSQL for scalable, high-performance, flexible data models.

SQL (RDS): Used for structured, relational, transactional data ‚Äî example: user accounts, orders, and payments in an e-commerce application.
NoSQL (DynamoDB): Used for high-scale, low-latency, flexible data ‚Äî example: user sessions, shopping carts, or real-time gaming leaderboards.

When would you choose DynamoDB over RDS?
When the application needs massive scalability, low latency, and doesn‚Äôt require joins or complex transactions





what is aws lammbada
  AWS Lambda is a serverless compute service provided by Amazon Web Services (AWS). It allows you to run your code without 
 provisioning or managing servers. You simply upload your code to Lambda, and it automatically handles the infrastructure, 
 scaling, and execution for you.

Lambda is not used to host full applications; it is used for event-driven and background processing, while core application  
logic runs on EKS or EC2.

App calls backend API: 
3Ô∏è‚É£ Backend (Lambda / EKS app) creates a pre-signed S3 URL
4Ô∏è‚É£ Backend sends URL back to frontend 
5Ô∏è‚É£ Frontend uploads file directly to S3 ,
6Ô∏è‚É£ File stored securely in S3 
7Ô∏è‚É£ S3 triggers Lambda for processing
Patient uploads file ‚Üí S3
S3 triggers Lambda
Lambda processes file ‚Üí stores result in RDS
Application (EKS) reads data from RDS

What problem SQS (Simple Queue service) solves 
Imagine:
One service sends work
Another service processes it
If the processor is slow or down ‚Üí data should NOT be lost
üëâ SQS holds messages safely until they are processed

üîπ Simple definition (interview ready)
Amazon SQS is a managed message queue that enables asynchronous communication between services by temporarily storing 
messages until they are processed.


1Ô∏è‚É£ Scalability (BIGGEST reason)
Healthcare apps have unpredictable traffic:
10 uploads today
10,000 uploads tomorrow
Why this design works
S3 scales automatically for any file size/count
Lambda scales automatically per event
EKS app stays stable and lightweight
üëâ No manual scaling needed
üó£ Real-world reason:
Hospitals cannot predict upload volume; this architecture handles spikes automatically.

üîπ 2Ô∏è‚É£ Cost Optimization (VERY IMPORTANT)
Without this design:
Backend servers handle file uploads
Servers must stay running 24/7
High EC2/EKS costs
With this design:
File uploads go directly to S3
Lambda runs only when needed
Pay only per request
üëâ No idle cost
üó£ Interview line:
We reduce infrastructure cost by offloading file uploads to S3 and using Lambda for event-based processing.

üîπ 3Ô∏è‚É£ High Availability (Healthcare requirement)
S3 is multi-AZ by default
Lambda runs across multiple AZs
RDS can be Multi-AZ
EKS pods spread across AZs
üëâ If one AZ fails ‚Üí system still works
üó£ Real-world reason:
Patient data must always be accessible.

üîπ 4Ô∏è‚É£ Security & Compliance (CRITICAL in healthcare)
No public S3 access
No AWS keys on frontend
Pre-signed URLs expire
IAM least privilege
Encryption at rest & in transit
üëâ Meets HIPAA / healthcare security standards
üó£ Interview line:
Pre-signed URLs allow secure uploads without exposing AWS credentials.

üîπ 7Ô∏è‚É£ Reliability & Fault Tolerance
If Lambda fails ‚Üí retry automatically
Can use DLQ (Dead Letter Queue)
Data not lost
üëâ Critical for medical data


Why companies don‚Äôt put full apps in Lambda
Reason               	Explanation
Time limit	         Max 15 minutes
Cold start	      Delay on first request


                                                            S3
 
Q what is S3?
   Amazon S3 (Simple Storage Service) is an object storage service provided by AWS. It allows you to store and retrieve any  
   amount of data from anywhere on the internet.

how s3 save or retrieve the data 
   Amazon S3 stores your files in buckets on AWS servers and gives each file a unique URL. You can upload, download, or 
   access  your data from anywhere using the internet, AWS console, CLI, or API.

what is deff btwn S3 bucket and object 
   Objects are the files that we save in S3, and buckets are the locations where we save those objects.

what is ACLs
   we use ACl only when we want to share bucket/object access with another AWS account.

what is versioning in s3
   Versioning is used when we want to keep multiple versions of the same file in S3
   Without versioning ‚Üí old file is overwritten (lost)
   With versioning ‚Üí both files are saved as different versions.

what is obejct lock in s3
   Lock the file so nobody can delete or change it.

   When Object Lock is enabled:
   You upload a file ‚Üí it becomes write-protected
   No one can delete or change it
   Protection stays active until the retention period ends
üìå Two Modes of Object Lock
   1. Governance Mode
     Only special users (with permission) can delete/modify
     Normal users cannot delete/modify
   2. Compliance Mode
     No one can delete/modify the object
     Even root user or admin cannot remove it
     Most secure (used for legal purposes)

static web hosting using s3
    for that we need to go to properties in properties section in the last we have static web hsoting option 
   
    403 forbidden means - permission error (give the permission policy getobject policy)
    404 not found means - index.html is missing (for that we need to save the inde.html file or error.html file on s3 bucket)

REPLICATION - by default aws will replicate in 3 availability zones or we can also do manually
            in this we have SRR and CRR
   SRR - Copies objects from one bucket to another bucket in the SAME region.
   CRR - Copies objects from one region to another region.

                                                 IAM 

what is IAM..?
      IAM (Identity and Access Management) 
      In short, IAM ensures that the right people have the right access to the right resources.

USER - User is an identity that represents a person or application which needs access to AWS services.
      Username
      Password (for Console login)
      Access keys (for CLI or API access)
      Permissions (what the user can or cannot do)

USER GROUP - Collection of users or we can say group of user
POLICY - A Policy defines permissions ‚Äî what actions are allowed or denied for a user, group, or role.
      what user group and role can do
IDENTY PROVIDER - IdP is used to let users from external accounts like Azure, GitHub, or Google access AWS without creating 
      new IAM users.
ROLES - Roles are used to give temporary access to someone or something.
      Example
      You have an EC2 instance that needs to access S3.
      Instead of giving IAM user credentials, you attach a role to the EC2.
      The instance can now access S3 temporarily and securely.

      we can say when we want to give the permission of any resource diectly to the ec2 for that we creates ROLES,
      like we can create roles for s3 for rds.

                                            AWS-CLI

AWS CLI - The AWS CLI is a powerful tool that allows you to manage AWS resources from the command line,
          
          to install aws cli we can directly install using "sudo apt install awscli" or for latest version we can go to the 
          officiall documentation of aws and after that we can download aws cli zip file using curl( from documentation) 
          command after that we need to unzip that file but for that we need unzip tool in our sysytem.
          "sudo apt install unzip" using this we can install unzip tool 
           After that we can unzip aws cli file.

to log in to aws throu CLI for that we run A command "aws configure"
    after that we need Access key id and secret access key or region name (we can use none also for this resgion):

to access any s3 bucket we use " aws s3 ls bucket-name"

to copy the object or file from s3 to local.- " aws s3 cp aws;//bucke-name/object-name .   
   ( . is for the curent loction.if we want to download somewhere lese we can give that path )
to copy the file from local to s3- "aws s3 cp file-name s3://bucket-name/

to sync the file from s3 to local.- " aws s3 sync aws://bucket-name/ .  
to sync the file from local to s3- "aws s3 sync file-name s3://bucket-name/



24. what is vpc and its components.?
A VPC (Virtual Private Cloud) is like your own private network in the AWS cloud where you can run your applications and store data securely.
Main parts of a VPC:
Subnets: Small sections of your VPC where you place resources. Some can connect to the internet (public), and some stay private (not connected to the internet).
IP Range CIDR (classles internet domain range Block): The range of IP addresses your VPC can use (like 10.0.0.0/16).

Route Tables: Controls traffic routing inside the VPC
              Each subnet must be associated with a route table.

Internet Gateway: A connection that allows your VPC to talk to the internet.

NAT Gateway/Instance:Allows private subnet resources to access the internet ‚ùå Internet cannot access them back it will connect the  
public subnat to private subnet

Security Groups: Firewalls that control which traffic is allowed to reach your resources.

What is NACL (Network Access Control List)?
A NACL (Network Access Control List) is a subnet-level firewall in a VPC that controls inbound and outbound traffic to and from subnets.

 VPC Endpoint -- A VPC Endpoint allows your resources in a private subnet to access AWS services privately, without using the Internet, IGW, or NAT Gateway.
Without VPC Endpoint:
Private EC2 ‚Üí NAT Gateway ‚Üí Internet ‚Üí S3

With VPC Endpoint:
Private EC2 ‚Üí VPC Endpoint ‚Üí S3

Real-time example
App in private subnet uploads logs to S3
No NAT Gateway needed

vpc->subnet->internet gateway->route table-> then assosiate the subnet to rout table -> then route the internete gateway

it is work like we create vpc first then we create subnets it will be private or public then we create internet gateway then 
we create route tables then we add(assosiate) subnet to route table and add rout, internet gateway to route table..

it works like route table is sits between subnets and internet gateway.
and nat gateway sits between private and public subnet.

what is vpc peering?
VPC Peering is a private network connection between two VPCs that allows resources in both VPCs to communicate using private IP addresses.
Inter-Region VPC Peering allows you to privately connect two VPCs that are in different AWS regions using AWS‚Äôs global backbone network.

Step 1: Check CIDR Blocks
Ensure CIDRs do not overlap.
Example:
VPC-A: 10.0.0.0/16
VPC-B: 10.1.0.0/16

üî∏ Step 2: Create VPC Peering Connection
AWS Console
Go to VPC ‚Üí Peering connections
Click Create peering connection
Select:
Requester VPC
Accepter VPC
Region / Account
Create
Status: Pending Acceptance

üî∏ Step 3: Accept the Peering Request
Go to accepter VPC
Accept request
Status: Active

üî∏ Step 4: Update Route Tables (MOST IMPORTANT üî•)
In VPC-A Route Table    # set the VPC-B in VPC-A
Destination: 10.1.0.0/16  # this is the VPC-B range
Target: pcx-xxxx

In VPC-B Route Table     # set the VPC-A in VPC-B
Destination: 10.0.0.0/16  # this is the VPC-A range
Target: pcx-xxxx       
Without this ‚Üí ‚ùå no connectivity

üî∏ Step 5: Update Security Groups
Allow traffic from peered VPC CIDR.
Example (DB SG in VPC-B):
Inbound:
MySQL 3306 ‚Üí Source: 10.0.0.0/16

Ping / Connectivity testing
For testing connectivity:
Protocol: ICMP
Port: All (ICMP doesn‚Äôt use ports)

üî∏ Step 6: Test Connectivity
From EC2 in VPC-A:
ping 10.1.x.x
telnet 3306

üß™ Real-Time Example
Scenario
App servers in VPC-A
Database in VPC-B
Flow
App EC2 ‚Üí VPC Peering ‚Üí RDS

What is transit Gateway
Transit Gateway is used to centrally connect multiple VPCs and on-prem networks instead of creating many VPC peerings.
Imagine you have many VPCs:
VPC-A (App)
VPC-B (Database)
VPC-C (Logging)
VPC-D (Monitoring)

Instead of VPCs connecting to each other,
üëâ all VPCs connect to ONE place (Transit Gateway).
        VPC-A
          |
        VPC-B
          |
      Transit Gateway
          |
        VPC-C
          |
    On-Prem Network

Use Transit Gateway when:
You have many VPCs
You need VPC-to-VPC communication
You need on-prem ‚Üí AWS connectivity
You want simple & scalable networking

Go to AWS Console ‚Üí VPC ‚Üí Transit Gateways ‚Üí Create Transit Gateway
Provide a name and create the Transit Gateway (TGW)
Go to Transit Gateway Attachments ‚Üí Create attachment
Select VPC, choose the VPC and its private subnets, then attach
Repeat attachment for all VPCs you want to connect
Open VPC route tables of each attached VPC
Add route: Destination = other VPC CIDR, Target = Transit Gateway
Verify Transit Gateway route table has routes for all VPC CIDRs
Update Security Groups / NACLs to allow required traffic
Test connectivity using private IPs

Create TGW ‚Üí Attach VPCs ‚Üí Update Route Tables ‚Üí Allow Security ‚Üí Test

Add route: Destination = other VPC CIDR, Target = Transit Gateway
VPC-A CIDR: 10.0.0.0/16
VPC-B CIDR: 10.1.0.0/16

Now go to VPC-A route table and add:
Destination: 10.1.0.0/16
Target: Select Transit Gateway
Choose your Transit Gateway ID (tgw-xxxx)
Click Save changes

Repeat for Other VPC
Now go to VPC-B route table and add:
Destination: 10.0.0.0/16
Target: Transit Gateway (tgw-xxxx)
Save changes

What You Just Did (Simple Words)
Told VPC-A:
üëâ ‚ÄúTo reach VPC-B, send traffic to Transit Gateway‚Äù
Told VPC-B:
üëâ ‚ÄúTo reach VPC-A, send traffic to Transit Gateway‚Äù



Q   What is geo-targeting in CloudFront?
it is a process which is used to serve the content based on their geographic location.
eg; English content for users in the US

Q  What is an Elastic Transcoder?
 It allows users to conversion of the media files, convert video and audio files from one format to another.

AWS Snowball is a physical data transport appliance used to securely transfer large volumes of data from on-premises 
systems to AWS cloud storage.To transfer terabytes of data outside and inside of the AWS environment, a small application
called SnowBall is used. 

snowball edge is a advance version of snowball which has extra feature like before transfer the data we can process the 
data locally 

 What is Amazon EC2?
Amazon EC2 (Elastic Compute Cloud) is a web service provided by Amazon Web Services (AWS) that allows users to rent virtual 
servers, known as instances, in the cloud.

1 diff between authorization and authentication.
       Authentication
       Purpose: Verifies who the user is.
       means the person who is looking for the access, he needs authentication using username password and other things.
       Authorization:
       Purpose: Determines what the user is allowed to do.
       means who gives the access or allowed to do anything.

3. Instance type in AWS.
      In AWS, an instance type defines the hardware specifications (such as CPU, memory, storage, and networking capacity) 
      of a virtual server (called an EC2 instance) that you can launch in the cloud.
      Choosing the right instance type depends on:
      Workload: Whether it's CPU, memory, or storage-intensive.
      Cost: Some instance types are more expensive based on their specifications.
      Performance: Choose an instance that matches your performance requirements for a given application.

4.  Different way to connect with ec2.
    1. SSH (Secure Shell) for Linux/Unix-based EC2 Instances
    What it is: SSH is a protocol used to securely connect to a Linux/Unix-based EC2 instance.
    How to use:
    Ensure you have the private key (.pem file) associated with the EC2 instance.
    Open a terminal or command prompt.
    2. EC2 Instance Connect (Browser-based SSH for Linux)
    3. Third-Party Tools (e.g., PuTTY, MobaXterm for SSH)

5. region vs availibility zones.
   Definition: A Region is a geographically isolated location that contains multiple data centers.
   Definition: An Availability Zone is a physically isolated data center within a region. Each region typically contains multiple Availability Zones.

6.list of globel services in AWS.
1. Amazon Route 53
Service Type: Domain Name System (DNS) and Domain Registration
Amazon Route 53 is a scalable and highly available Domain Name System (DNS) service that routes traffic by translating 
 human-readable domain names (e.g., www.example.com) into IP addresses that computers use to identify each other. 
 Additionally, Route 53 supports domain name registration, allowing you to purchase and manage domain names directly within 
 AWS."

2. AWS Identity and Access Management (IAM)
Service Type: Security and Access Management
Description: Manages user access to AWS services and resources across all regions. IAM policies, roles, and users are global.

3. Amazon CloudFront
Service Type: Content Delivery Network (CDN)
Amazon CloudFront is a Content Delivery Network (CDN) that helps deliver your content, such as websites, images, videos, 
and apps, to users faster. 
It works by copying your content to servers (called edge locations) around the world.
When someone requests your content, CloudFront sends it from the nearest server

4. Amazon S3 (with Global S3 Access Points)
Amazon S3 (Simple Storage Service) is a cloud storage service provided by Amazon Web Services (AWS)
that allows you to store and retrieve any amount of data at any time from anywhere on the web.

5. AWS CloudTrail
Amazon CloudTrail is a service provided by AWS that helps you monitor and log all the activities and API calls made in your 
AWS account.
It automatically records detailed information about every action taken on AWS resources, such as who did what and when.

6. Amazon SNS (Simple Notification Service)
Service Type: Messaging and Notification
Description: A fully managed messaging service for sending notifications globally, including email, SMS, and other protocols.

7. Amazon CloudWatch
Amazon CloudWatch is a monitoring and observability service provided by AWS that helps you track the performance, 
health, and activity of your AWS resources and applications in real-time.
CloudTrail focuses on tracking API calls and providing an audit trail of actions in your AWS account.
CloudWatch focuses on monitoring the health and performance of your AWS resources, providing metrics, logs, and alarms.


7. what is elastic ip.
   elastic ip is used to get a permanent ip adress of any server to ensure high availibility of the server.

8. what is auto scalling.
   auto scalling help you to ensure high availibility of the server it will automatically scale-up and scale-down the server and resources according to the workload and performance.

9. load balancer and its type.
A Load Balancer is a service that automatically distributes incoming traffic across multiple servers 
or resources to ensure high availability, reliability, and optimal performance of your application
Application Load Balancer (ALB):
Sends web traffic to the right server based on the URL (like sending image requests to one server and API requests to another).

Network Load Balancer (NLB):
Sends fast traffic (like games or streaming) to the right server.

Classic Load Balancer (CLB):
Old load balancer that just sends regular traffic to servers.

10. ALB vs NLB
ALB is for web traffic with complex routing (like websites).
NLB is for high-speed, real-time traffic (like gaming or video streaming).

11. security groups vs NACL
Security Groups are used for instance-level security, allowing only specified inbound traffic, while automatically handling return traffic.
NACLs Network Access Control Lists are used for subnet-level security, allowing more granular control with both allow and deny rules for traffic in and out of the subnet.

12. S3 Object Lifecycle:
Lifecycle policies let you automatically manage your data:
Transition: Move data to cheaper storage after a certain time (e.g., from Standard to Glacier).
Expiration: Automatically delete data after a set time.

13. AMI vs SNAPSHOT
AMI An AMI is a pre-configured image based on existing image we use ami for a reapititive task like if we want to use all the configuration of a instance in future for that
we can create the AMI based on that instance,
SNAPSHOT it is used for the backup up EBS volume of the instance the EBS volume of the instance we can take manually or we can take on a perticulor time for that we use
 lifecycle policy for the taking the snapshot daily.

14. what is ECS 
Amazon ECS (Elastic Container Service) is a fully managed container orchestration service provided 
by AWS (Amazon Web Services) that allows you to easily run, manage, and scale containerized applications on AWS. 

15. RDS service  realtional database service
database - it is collection of tables
table - it is collection of rows and collumbs 

RDS is used to your database service. For database engine we need rds service
It supports multiple database engines like MySQL, SQL Server, Oracle, and Amazon Aurora, 
 mysql - it is structured quaery language. it uses tables to store the data.
   - The INSERT INTO statement is used to add new records to a table. 
   - The UPDATE statement is used to modify existing records in a table. 
   - The DELETE statement is used to remove records from a table.
   - The CREATE TABLE statement is used to create a new table in a database.
   - The DROP TABLE statement is used to delete a table and all its data.
   - The JOIN clause is used to combine rows from two or more tables, based on a related column.
Oracle- Oracle Database is a powerful system used to store and manage large amounts of data.
             Oracle is often used in large businesses because it ensures data is safe, organized, and easily accessible.
 
mongodb MongoDB is a popular NoSQL database that is designed to store large amounts of data in a flexible, scalable.

16. what is cloudformation and stack in cloudformation.
it is used to provisioning the AWS resources, we can provisioning only AWS resources using cloudFormation.
Infrastructure as Code (IaC): Define your infrastructure in code, which can be version-controlled and reused.
Automated Provisioning: Automatically creates, updates, and deletes AWS resources based on your templates.

stack in cloudformation
   A CloudFormation Stack is essentially a collection of AWS resources
   if you have a CloudFormation template that defines an EC2 instance, an S3 bucket, and a security group, these resources will be grouped into a stack. 
   If you need to make changes to the resources (e.g., update an EC2 instance type or add a new S3 bucket), you can modify the template and update the entire stack.
 Resources:
  MyEC2Instance:
    Type: AWS::EC2::Instance
    Properties:
      InstanceType: t2.micro
      ImageId: ami-0c55b159cbfafe1f0
      KeyName: my-key-pair

17. cloud deployment models
public 
private 
hybrid and 
community cloud.

18 cloud service model.
Iaas   You manage: The operating system, applications, and data.
paas   You manage: Your applications and data.
saas   You manage: Nothing. You just use the application.

19. what is amazon resource name 
 an ARN is just a way to name and find things in AWS.

20.  CNAME (Canonical Name) 
It‚Äôs commonly used to alias one domain name to another

21.  What is AAA in aws 
Authentication verifies who you are.
Authorization defines what you can do.
Accounting tracks what you did and when.

22. what is AWS secret manager.
    it is used to secure save and retrive the credentials and sensitive data.



25. diff b/w roles and policies.?
Roles:
A Role is like a set of permissions that you can assign to an AWS resource (such as an EC2 instance, Lambda function, or user).
Policies:
A Policy is a document that defines what actions are allowed or denied on specific AWS resources.

26. types of scalling of ec2 in aws
Vertical Scaling: Change the size of a single instance.
Horizontal Scaling: Add or remove multiple instances to handle traffic.

27 access controle list vs bucket policy
ACL is basic and works for specific users or objects.
Bucket Policy is more advanced, applies to the whole bucket, and can include complex rules.

28. edge location.
An Edge Location in AWS is a location where AWS CloudFront caches content for fast delivery to users. 

29. what is ssl and tls certificates.
SSL (Secure Sockets Layer):
SSL is the older protocol that was originally used to secure communications between web browsers and servers.
TLS Transport Layer Security is modern protocall it is more secure version of SSL.
SSL/TLS certificates help keep your data safe when browsing by securing the communication between your browser and a website.

30 EBS vs EFS
EBS is for single-instance storage, while EFS is for shared storage across multiple instances at a same time.

31  What is AWS CodePipeline
 AWS CodePipeline is a fully managed continuous integration and continuous delivery (CI/CD) service that automates the 
 build, test, and deployment phases of your application. 


33What other aws services are used with AWS CodePipeline
 1. AWS CodeCommit
Purpose: CodeCommit is a source control service that you can use as the source stage in CodePipeline.
 2. AWS CodeBuild
Purpose: CodeBuild is a fully managed build service that compiles your code, runs tests, and produces deployable artifacts.
 3. AWS CodeDeploy
Purpose: CodeDeploy automates the deployment of applications to Amazon EC2 instances, AWS Lambda, or Amazon ECS.
 4. Amazon Elastic Container Service (ECS)
Purpose: ECS is a container orchestration service for running Docker containers.
 5. Amazon Elastic Kubernetes Service (EKS)
Purpose: EKS is a managed Kubernetes service to run containerized applications.

34 What is the objective of the code pipeline
  the abjective is to automate the process of building testing and deployint hte application

35 How does code build work
  AWS CodeBuild is a fully managed continuous integration (CI) service that automates the process of compiling source code, 
  running tests, and producing artifacts 

36 What are the different types of storage in AWS
  (EBS, EFS, S3

37 How does AWS Route 53 work?
  Amazon Route 53 is a scalable and highly available Domain Name System (DNS) service that routes traffic by translating 
  human-readable domain names (e.g., www.example.com) into IP addresses that computers use to identify each other. 
  Additionally, Route 53 supports domain name registration, allowing you to purchase and manage domain names directly 
  within AWS."

38. Explain AWS CloudFormation and how it differs from Terraform.
  Using AWS CloudFormation, you can only provision and manage AWS resources, as it is specifically designed for the AWS 
  ecosystem. On the other hand, Terraform is a multi-cloud tool that allows you to provision resources across various cloud 
  platforms, including AWS, Azure, Google Cloud, and more."

39. What is AWS Fargate, and how does it work?
   it is a serverless compute engine it can be integrate by both services ECS EKS 
   it is used to run containers (e.g., Docker containers) without managing the underlying servers or infrastructure.
When you deploy the application on ECS or EKS using Fargate, AWS handles the provisioning of the underlying infrastructure 
 (such as EC2 instances) automatically.
You only need to specify the CPU and memory requirements for the containers in your task definition or pod specification. 
 Fargate takes care of everything else, including scaling and load balancing.

40 what services will give you high availability, fault tolarance, scalability in aws
Amazon CloudFront
High Availability: CloudFront is a Content Delivery Network (CDN) that caches content at edge locations globally, ensuring 
 fast and reliable content delivery.
Fault Tolerance: CloudFront automatically routes traffic to the nearest healthy edge location in case one fails.
Scalability: CloudFront scales automatically to accommodate large numbers of concurrent users and high data traffic.

auto scalling 
High Availability: Auto Scaling automatically adjusts the number of EC2 instances in a scaling group, ensuring that your 
 application has enough resources to handle traffic and is highly available.
Fault Tolerance: Auto Scaling can replace unhealthy instances and launch new instances to maintain desired capacity, 
 ensuring that the application stays fault-tolerant.
Scalability: Auto Scaling scales up or down based on load (CPU, network traffic, etc.), ensuring the application can handle 
 changes in demand without manual intervention.

 Elastic Load Balancing (ELB)
High Availability: ELB distributes incoming traffic across multiple targets (EC2 instances, containers, etc.) across different AZs, improving availability.
Fault Tolerance: ELB automatically detects unhealthy instances and reroutes traffic to healthy instances, ensuring continuous service even if one instance fails.
Scalability: ELB automatically adjusts to the incoming traffic load and distributes it accordingly to ensure balanced performance.

 Amazon S3 (Simple Storage Service)
High Availability: Amazon S3 is designed to be highly available across multiple geographic regions. It automatically replicates data across multiple AZs within a region.
Fault Tolerance: S3 automatically handles data replication and can recover from failures, ensuring that your data is durable and available even if part of the system fails.
Scalability: S3 scales automatically to accommodate large amounts of data without any manual intervention, offering virtually unlimited storage.

how can i create custom policies in aws
 using iam services.



What is AWS?

What are the key components of AWS?

What is EC2 in AWS?

Explain the difference between EC2 instance types.

What is S3?

What are the different storage classes available in S3?

How does S3 ensure data durability?

What is an IAM role?

How do IAM roles differ from IAM users?

What is VPC?

What are subnets in AWS?

What is an Internet Gateway?

What is a NAT Gateway?

What are security groups?

What are Network ACLs?

How do Security Groups differ from Network ACLs?

What is AWS Lambda?

What is the difference between AWS Lambda and EC2?

What is CloudFormation?

How does CloudFormation work?

What is Elastic Load Balancer (ELB)?

What are the different types of ELB?

What is Auto Scaling?

How does Auto Scaling work?

What is Route 53?

What is the difference between Route 53 and traditional DNS?

What are AWS Availability Zones?

What is the difference between an AWS Region and Availability Zone?

What is CloudWatch?

How do you monitor resources with CloudWatch?

What is AWS CloudTrail?

How does CloudTrail differ from CloudWatch?

What is an Elastic IP?

What is the difference between public and private IP addresses?

What is EBS in AWS?

How do EBS volumes differ from instance store?

What is a snapshot in AWS?

How do you secure data in S3?

What are S3 buckets?

What is the maximum size of an S3 object?

What is AWS RDS?

What are the different database engines supported by RDS?

What is Multi-AZ deployment in RDS?

What is read replica in RDS?

How do you backup and restore an RDS database?

What is AWS Elastic Beanstalk?

How does Elastic Beanstalk work?

What is AWS IAM?

What is the principle of least privilege in AWS?

What are AWS CloudFront and its use case?

How does CloudFront work with S3?

What is an AWS Lambda trigger?

What is a VPC Endpoint?

What is the difference between a gateway and an interface VPC Endpoint?

What is AWS SNS?

What is AWS SQS?

How do SNS and SQS differ?

What is AWS Elasticache?

What are the caching strategies supported by AWS Elasticache?

What is AWS Glacier?

When do you use AWS Glacier?

What is AWS KMS?

How do you encrypt data in AWS?

What is a CloudFormation stack?

What is AWS OpsWorks?

What is AWS Config?

How do you use AWS Config for compliance?

What is AWS Trusted Advisor?

What are AWS pricing models?

What is AWS Free Tier?

How do you secure AWS resources?

What is AWS Shield?

What is AWS WAF?

How does AWS help with DDoS protection?

What is AWS Elastic Container Service (ECS)?

What is AWS Fargate?

How does ECS differ from EKS?

What is AWS EKS?

What is a launch configuration?

How do you perform blue-green deployment in AWS?

What is AWS CloudTrail log file validation?

How does AWS handle identity federation?

What is an AWS endpoint?

What are AWS Tags?

What is a Bastion Host?

How do you secure access to AWS instances?

What is AWS CodePipeline?

What is AWS CodeBuild?

What is AWS CodeDeploy?

What is AWS CodeCommit?

What is the difference between AWS CodePipeline and Jenkins?

How do you automate deployments with AWS?

What is an Elastic Beanstalk environment?

What is AWS SSM?

How do you use SSM Parameter Store?

What is the difference between AWS S3 and EFS?

What is AWS Direct Connect?

How does AWS support hybrid cloud?

What are the limitations of AWS Lambda?

How do you optimize AWS costs?














